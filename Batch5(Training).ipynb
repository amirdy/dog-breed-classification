{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "net5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gh3tlsgDy-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd \n",
        "import random\n",
        "import gc\n",
        "import torch.cuda as cuda\n",
        "from google.colab import drive\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import ImageFile\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Z00ikOPhzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "EFNet = EfficientNet.from_pretrained('efficientnet-b3')\n",
        "print(EFNet)\n",
        "EFNet._fc = torch.nn.Sequential()#1536\n",
        "for  name,param in EFNet.named_parameters():\n",
        "  if (\"bn\" not in name):\n",
        "    param.requires_grad = False\n",
        "EFNet.set_swish(memory_efficient=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp6t-VGlgXdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mlp(torch.nn.Module):\n",
        "  def  __init__(self,input_size, output_num):\n",
        "    super(mlp,self).__init__()\n",
        "    self.fc1=torch.nn.Linear(input_size,output_num)\n",
        " \n",
        "    self.relu=torch.nn.ReLU()\n",
        "    self.drop4= torch.nn.Dropout(p=0.8)\n",
        "    \n",
        "    \n",
        "  def forward(self,x):\n",
        "   \n",
        "    out=self.drop4(x)\n",
        "    out=self.fc1(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzquuHwtoMQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=mlp(1536 , 150)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWvJlbkTa6Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_transforms = {\n",
        "    # Train uses data augmentation\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=(400,350), scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=20),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225]) \n",
        "    ]),\n",
        "    # Validation does not use augmentation\n",
        "    'valid':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=(400,350)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvxn3cazu7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=\"/content/drive/My Drive/dog/batch5/train_dir/\", transform=image_transforms['train']),\n",
        "    'valid':\n",
        "    datasets.ImageFolder(root=\"/content/drive/My Drive/dog/batch5/valid_dir/\", transform=image_transforms['valid']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root=\"/content/drive/My Drive/dog/test_dir/\", transform=image_transforms['valid']),\n",
        "}\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZgu1BijH9eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples_lenght = len(data['train'])\n",
        "valid_samples_lenght = len(data['valid'])\n",
        "test_samples_lenght = len(data['test'])\n",
        "\n",
        "batch_size_train = 25\n",
        "batch_size_valid = 15\n",
        "numTrainBatches =  int(np.ceil(train_samples_lenght / batch_size_train))\n",
        "numValidBatches =  int(np.ceil(valid_samples_lenght / batch_size_valid))\n",
        "numTestBatches =  int(np.ceil(test_samples_lenght / batch_size_valid))\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(data['train'], batch_size=batch_size_train, shuffle=True),\n",
        "    'val': DataLoader(data['valid'], batch_size=batch_size_valid, shuffle=False),\n",
        "    'test': DataLoader(data['test'], batch_size=batch_size_valid, shuffle=False)\n",
        "\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZu-HlRh4igY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(numTrainBatches)\n",
        "print(numValidBatches)\n",
        "print(numTestBatches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KbxKvuXQxHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_accuracy(pred_classes,real_classes):#  shape ->  both : [number of test samples,]\n",
        "  bool_array=(pred_classes==real_classes) # example: bool_array=[True, False, True, False, True]\n",
        "  True_pred_counts=np.count_nonzero(bool_array) # count number of Trues in [True, False, True, False, True]\n",
        "  return True_pred_counts/pred_classes.shape[0]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtr3W1RRTLMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(), betas=(0.9, 0.999), eps=1e-08,lr=0.0001)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH1O0INPTWLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minloss= 0.3\n",
        "train_loss=0\n",
        "test_loss=0\n",
        "for i in range(150):\n",
        "  ac=0\n",
        "  train_loss=0\n",
        "  test_loss=0\n",
        "  trainiter = iter(dataloaders['train']) \n",
        "  for k in range(numTrainBatches):\n",
        "    x, y = next(trainiter) #features: torch.Size( batch_size, 3 ,400, 350) , labels: torch.Size(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "    if cuda.is_available():\n",
        "          x = x.cuda()\n",
        "          y = y.cuda()\n",
        "\n",
        "          EFNet = EFNet.cuda()\n",
        "          model = model.cuda()\n",
        "    \n",
        "    EFNet.eval()\n",
        "    model.train()\n",
        "    \n",
        "    x = EFNet(x)\n",
        "    outputs=model(x) #output: torch.Size([batchsize, 150])  | 150 is number of output neurons\n",
        "    \n",
        "    \n",
        "    loss=criterion(outputs,y)\n",
        "    train_loss += loss.data\n",
        "\n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()\n",
        "\n",
        "    pred_classes=torch.max(outputs.data, 1)[1]\n",
        "    acc=cal_accuracy(np.array(pred_classes.cpu()),np.array(y.cpu()))\n",
        "    ac=acc+ac\n",
        "\n",
        "\n",
        "\n",
        "    del outputs\n",
        "    del loss\n",
        "    del x\n",
        "    del y\n",
        "    del pred_classes\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    torch.cuda.memory_allocated()\n",
        "    torch.cuda.empty_cache() \n",
        "\n",
        "  print(\"Epoch: \",i+1,\" Train loss=\",train_loss/numTrainBatches,\" Accuracy: \",ac*100 / numTrainBatches)\n",
        "  gc.collect()\n",
        "  ac=0\n",
        "  validiter = iter(dataloaders['val']) \n",
        "  for k in range(numValidBatches):\n",
        "    xx, yy = next(validiter) #features: torch.Size( batch_size, 3 ,400, 350) , labels: torch.Size(batch_size)\n",
        "    \n",
        "\n",
        "    if cuda.is_available():\n",
        "          xx = xx.cuda()\n",
        "          yy = yy.cuda()\n",
        "\n",
        "          EFNet = EFNet.cuda()\n",
        "          model = model.cuda()\n",
        "\n",
        "\n",
        "    EFNet.eval()\n",
        "    model.eval()\n",
        "\n",
        "    xx = EFNet(xx)\n",
        "    outputss=model(xx) # output: torch.Size([batchsize, 150])  | 150 is number of output neurons\n",
        "\n",
        "    loss=criterion(outputss,yy)\n",
        "    test_loss=test_loss+loss.data\n",
        "    pred_classes=torch.max(outputss.data, 1)[1]\n",
        "    acc=cal_accuracy(np.array(pred_classes.cpu()),np.array(yy.cpu()))\n",
        "    ac=acc+ac\n",
        "\n",
        "\n",
        "    del outputss\n",
        "    del loss\n",
        "    del xx\n",
        "    del yy\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache() \n",
        "  print(\"Epoch: \",i+1,\" Test loss=\",test_loss/numValidBatches,\" Accuracy: \",ac*100 / numValidBatches)\n",
        "  if (test_loss/numValidBatches)< minloss:\n",
        "    print(\"hopLoss\")\n",
        "    minloss=test_loss/numValidBatches\n",
        "    PATH=\"/content/drive/My Drive/dog/net5.pth\"\n",
        "    torch.save({\n",
        "\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "  \n",
        "              }, PATH)\n",
        "       \n",
        "  \n",
        " \n",
        "print(ac) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gDHhznXaTZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TEST ###\n",
        "model=mlp(1536 , 150)\n",
        "PATH=\"/content/drive/My Drive/dog/net5.pth\"\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.cuda()\n",
        "\n",
        "test_loss=0\n",
        "ac = 0 \n",
        "testiter = iter(dataloaders['test']) \n",
        "for k in range(numTestBatches):\n",
        "    xx, yy = next(testiter) #features: torch.Size( batch_size, 3 ,400, 350) , labels: torch.Size(batch_size)\n",
        "    \n",
        "\n",
        "    if cuda.is_available():\n",
        "          xx = xx.cuda()\n",
        "          yy = yy.cuda()\n",
        "\n",
        "          EFNet = EFNet.cuda()\n",
        "          model = model.cuda()\n",
        "\n",
        "\n",
        "    EFNet.eval()\n",
        "    model.eval()\n",
        "\n",
        "    xx = EFNet(xx)\n",
        "    outputss=model(xx) # output: torch.Size([batchsize, 150])  | 150 is number of output neurons\n",
        "\n",
        "    loss=criterion(outputss,yy)\n",
        "    test_loss=test_loss+loss.data\n",
        "    pred_classes=torch.max(outputss.data, 1)[1]\n",
        "    acc=cal_accuracy(np.array(pred_classes.cpu()),np.array(yy.cpu()))\n",
        "    ac=acc+ac\n",
        "\n",
        "\n",
        "    del outputss\n",
        "    del loss\n",
        "    del xx\n",
        "    del yy\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache() \n",
        "print(\" Test loss=\",test_loss/numTestBatches,\" Accuracy: \",ac*100 / numTestBatches)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}